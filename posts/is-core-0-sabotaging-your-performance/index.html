<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="canonical" href=https://kish1n.github.io/posts/is-core-0-sabotaging-your-performance/>
    <link rel="alternate" type="application/rss+xml" href="/feed.xml" title="Feed">

    <link href="/assets/main.df9f7c4e70c97edb71fe.css" rel="stylesheet" />

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans&display=swap" rel="stylesheet">

    <title>
      Is Core 0 Sabotaging Your Performance?
      
         | Ashwin Kishin Banwari
      
    </title>

    <link rel="icon" type= “image/png” href="/images/favicon.png">

    <meta property="og:title" content="Is Core 0 Sabotaging Your Performance?">
    <meta property="og:site_name" content="Ashwin Kishin Banwari"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://kish1n.github.io//posts/is-core-0-sabotaging-your-performance/"/>
    <meta name="twitter:card" content="summary_large_image">

    

    
    
    
      <meta name="description" content="An investigation into the discrepancy in observed performance between cores on a modern CPU">
      <meta property="og:description" content="An investigation into the discrepancy in observed performance between cores on a modern CPU">
      <meta name="description" content="An investigation into the discrepancy in observed performance between cores on a modern CPU"/>
    

    
      
    
    
      <meta property="og:image" content="https://kish1n.github.io/images/social-image.png"/>
      <meta name="twitter:image" content="https://kish1n.github.io/images/social-image.png"/>
    
  </head>
  <body>
    <div class="layout-wrapper">

      <header class="header">
        <div class="header__content">
          <h1 class="site-title">
            <a href=/>
              Ashwin Kishin Banwari
            </a>
          </h1>

          
            <nav class="nav">
              <ul class="nav__list">
                
                  
                  

                  

                  

                  <li class="nav-item">
                    <a href="/blog"  >Blog</a>
                  </li>
                
                  
                  

                  

                  

                  <li class="nav-item">
                    <a href="/about"  >About</a>
                  </li>
                
              </ul>
            </nav>

          

        </div>
      </header>

      <main class="main">
        
<article class="post">
  <header class="post__header">
    <h1>Is Core 0 Sabotaging Your Performance?</h1>
    <div class="post__details">
      <time datetime="2025-12-16">
        16 Dec 2025
      </time>
      <span> | </span>
      <span>4 min read</span>
    </div>
  </header>

  <main class="post__content">
    <p><strong>TL;DR:</strong> Not all CPU cores are equal—even beyond architectural differences like 3D V-Cache. On an AMD Ryzen 9 9950X3D, core 0 shows significantly worse tail latency due to the OS preferentially routing interrupts to it. For latency-sensitive applications, this hidden asymmetry can cause significant performance degradation.</p>
<h2>Introduction</h2>
<p>It is commonly known that CPUs these days often have different types of cores. For example, Intel has &quot;performance&quot; P-cores and &quot;efficiency&quot; E-cores. AMD's high core count CPUs advertised with 3D V-Cache only have some cores with access to the additional L3 cache, with the rest having the standard amount of L3 cache.</p>
<p>But are there significant differences between cores beyond what is advertised? By complete accident, I found the answer to this is <em>most definitely</em>.</p>
<h2>Background</h2>
<p>I was working on my tail latency microbenchmarking tool <a href="https://github.com/kish1n/cpptail">cpptail</a> and added functionality to pin the program to a CPU core of the user's choice. This enables consistent benchmarking as different types of cores are ... well ... different.</p>
<p>To sanity-check my implementation, I made a test script to run a simple mathematical benchmark for each of the 32 logical cores on my AMD Ryzen 9 9950X3D. My expectation was for cores 0-7 and 16-23 to perform slightly slower than the others, as they belong to the CCD with 3D V-Cache stacked on top. The extra cache layers add thermal constraints that reduce boost clocks—a primary factor in simple numerical benchmarks. While the prediction proved mostly true, there was something in the data that piqued my interest.</p>
<h3>Test Configuration</h3>
<ul>
<li><strong>CPU:</strong> AMD Ryzen 9 9950X3D</li>
<li><strong>OS:</strong> Linux (CachyOS 6.18)</li>
<li><strong>Benchmark Tool:</strong> <a href="https://github.com/kish1n/cpptail">cpptail</a></li>
<li><strong>Iterations:</strong> 1,000,000 per core</li>
</ul>
<h2>The Data</h2>
<p>Time it takes to run the benchmark for each core. Units in <strong>nanoseconds</strong>.</p>
<table>
<thead>
<tr>
<th>Core</th>
<th>Mean</th>
<th>p50</th>
<th>p99</th>
<th>p99.9</th>
<th></th>
<th>Core</th>
<th>Mean</th>
<th>p50</th>
<th>p99</th>
<th>p99.9</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>272</td>
<td>261</td>
<td>271</td>
<td>271</td>
<td></td>
<td>16</td>
<td>263</td>
<td>261</td>
<td>271</td>
<td>301</td>
</tr>
<tr>
<td>1</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
<td></td>
<td>17</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
</tr>
<tr>
<td>2</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
<td></td>
<td>18</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
</tr>
<tr>
<td>3</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
<td></td>
<td>19</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
</tr>
<tr>
<td>4</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
<td></td>
<td>20</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
</tr>
<tr>
<td>5</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
<td></td>
<td>21</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
</tr>
<tr>
<td>6</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
<td></td>
<td>22</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
</tr>
<tr>
<td>7</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
<td></td>
<td>23</td>
<td>262</td>
<td>261</td>
<td>271</td>
<td>271</td>
</tr>
<tr>
<td>8</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
<td></td>
<td>24</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
</tr>
<tr>
<td>9</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
<td></td>
<td>25</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
</tr>
<tr>
<td>10</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
<td></td>
<td>26</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
</tr>
<tr>
<td>11</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>290</td>
<td></td>
<td>27</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
</tr>
<tr>
<td>12</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>280</td>
<td></td>
<td>28</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
</tr>
<tr>
<td>13</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
<td></td>
<td>29</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
</tr>
<tr>
<td>14</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
<td></td>
<td>30</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
</tr>
<tr>
<td>15</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
<td></td>
<td>31</td>
<td>255</td>
<td>251</td>
<td>261</td>
<td>261</td>
</tr>
</tbody>
</table>
<p>The 3D V-Cache cores (0-7, 16-23) consistently show ~262ns mean latency, while non-V-Cache cores (8-15, 24-31) achieve ~255ns—a <strong>~2.7% performance difference</strong>. This aligns with expectations: the 3D V-Cache adds thermal constraints that reduce boost clocks.</p>
<p>One core stands out dramatically: <strong>core 0</strong> with 272ns mean latency. Even more suspicious, its mean latency exceeds its p99.9 latency, suggesting the distribution is heavily skewed by outliers. Compared to the non-V-Cache cores, core 0 shows a <strong>17ns (6.7%) latency penalty</strong>—and compared to other V-Cache cores, it's still 10ns slower.</p>
<p>Repeated runs showed identical patterns. Something systematic was happening on core 0.</p>
<h2>Effective Frequency Of Each Core</h2>
<p>After analyzing the results from a million iterations of the core 0 benchmark, I saw hundreds of execution times ranging from 1,000 to 23,000 nanoseconds—outliers that were completely absent from benchmarks of other cores. My immediate suspicion was context switches. Perhaps some stray process on my system was competing for core 0 during the benchmark. However, using the Linux <code>perf</code> utility, I found there were zero context switches, so that hypothesis was incorrect.</p>
<p>I then created a script to divide the cycles reported by <code>perf</code> by time to calculate what could be called an <em>effective frequency</em> for each core. This metric represents only the cycles spent on the benchmarking process, not the total cycles the core executed. I also collected IRQ counts (interrupt requests from hardware and the kernel) for each core.</p>
<table>
<thead>
<tr>
<th>Core</th>
<th>Freq (GHz)</th>
<th>IRQs</th>
<th></th>
<th>Core</th>
<th>Freq (GHz)</th>
<th>IRQs</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>5.33</td>
<td>111</td>
<td></td>
<td>16</td>
<td>5.54</td>
<td>35</td>
</tr>
<tr>
<td>1</td>
<td>5.54</td>
<td>50</td>
<td></td>
<td>17</td>
<td>5.53</td>
<td>46</td>
</tr>
<tr>
<td>2</td>
<td>5.54</td>
<td>29</td>
<td></td>
<td>18</td>
<td>5.54</td>
<td>58</td>
</tr>
<tr>
<td>3</td>
<td>5.55</td>
<td>31</td>
<td></td>
<td>19</td>
<td>5.54</td>
<td>45</td>
</tr>
<tr>
<td>4</td>
<td>5.54</td>
<td>33</td>
<td></td>
<td>20</td>
<td>5.55</td>
<td>49</td>
</tr>
<tr>
<td>5</td>
<td>5.54</td>
<td>35</td>
<td></td>
<td>21</td>
<td>5.54</td>
<td>57</td>
</tr>
<tr>
<td>6</td>
<td>5.53</td>
<td>62</td>
<td></td>
<td>22</td>
<td>5.54</td>
<td>49</td>
</tr>
<tr>
<td>7</td>
<td>5.53</td>
<td>33</td>
<td></td>
<td>23</td>
<td>5.54</td>
<td>43</td>
</tr>
<tr>
<td>8</td>
<td>5.68</td>
<td>35</td>
<td></td>
<td>24</td>
<td>5.69</td>
<td>34</td>
</tr>
<tr>
<td>9</td>
<td>5.69</td>
<td>26</td>
<td></td>
<td>25</td>
<td>5.69</td>
<td>27</td>
</tr>
<tr>
<td>10</td>
<td>5.69</td>
<td>27</td>
<td></td>
<td>26</td>
<td>5.69</td>
<td>33</td>
</tr>
<tr>
<td>11</td>
<td>5.69</td>
<td>43</td>
<td></td>
<td>27</td>
<td>5.69</td>
<td>31</td>
</tr>
<tr>
<td>12</td>
<td>5.69</td>
<td>36</td>
<td></td>
<td>28</td>
<td>5.69</td>
<td>31</td>
</tr>
<tr>
<td>13</td>
<td>5.69</td>
<td>35</td>
<td></td>
<td>29</td>
<td>5.70</td>
<td>40</td>
</tr>
<tr>
<td>14</td>
<td>5.69</td>
<td>34</td>
<td></td>
<td>30</td>
<td>5.69</td>
<td>37</td>
</tr>
<tr>
<td>15</td>
<td>5.69</td>
<td>31</td>
<td></td>
<td>31</td>
<td>5.69</td>
<td>28</td>
</tr>
</tbody>
</table>
<h2>IRQs: Source of Tail Latency?</h2>
<p>IRQs (Interrupt Requests) are treated specially by <code>perf</code>. Despite triggering a context switch to kernel interrupt handlers, saving processor state and suspending user-space execution, they don't increment the context switch counter. This explains why <code>perf</code> reported zero context switches!</p>
<p>The data reveals the root cause:</p>
<ul>
<li><strong>Core 0</strong>: 111 IRQs during benchmark execution, 5.33 GHz effective frequency</li>
<li><strong>Other 3D V-Cache cores</strong>: ~30-60 IRQs, ~5.54 GHz effective frequency</li>
<li><strong>Non-V-Cache cores</strong>: ~25-45 IRQs, ~5.69 GHz effective frequency</li>
</ul>
<p>Core 0 receives <strong>~3× more interrupts</strong> than other cores. These interrupts can include:</p>
<ul>
<li>Timer ticks</li>
<li>NIC (network interface) interrupts</li>
<li>Disk I/O completions</li>
<li>System management interrupts</li>
</ul>
<p>Each interrupt suspends user-space execution for hundreds of nanoseconds to microseconds. The Linux kernel defaults to preferring the first core for a significant amount of its heavier IRQs, making core 0 the primary victim. Interestingly, the interrupts that did occur on other cores also seemed to have less of an impact on their tail latency suggesting <em>heavier</em> IRQs on core 0.</p>
<p>This is validated by examining perf timing breakdown:</p>
<ul>
<li><strong>User time</strong>: Comparable across all cores (~1M operations worth)</li>
<li><strong>System time</strong>: Orders of magnitude higher on core 0 than other cores</li>
</ul>
<p>The tail latency spikes (1,000-23,000ns) occur precisely when IRQs fire during benchmark execution. On its own, it may not seem a lot, but hundreds to thousands of them occur each second on core 0, with the amount only increasing with added peripherals, audio processing, network traffic, etc.</p>
<h2>Conclusion</h2>
<p>CPU cores that may be commonly assumed to be identical can behave very differently in practice. Operating system decisions—especially how IRQs are distributed—introduce measurable performance gaps between supposedly equal cores. For real-time applications, understanding and controlling CPU affinity and interrupt distribution can provide substantial improvement. Linux gamers on dual-CCD AMD CPUs already manually control cores used by games with <code>taskset -c 0-7,16-23 %command%</code> to pin a game to the 3D V-Cache cores. The results from this experiment suggest it may be beneficial for them to remove core 0 from the pool!</p>
<p>Further reading:</p>
<ul>
<li><a href="https://www.kernel.org/doc/html/latest/core-api/irq/irq-affinity.html">Linux IRQ Affinity Documentation</a></li>
<li><a href="https://github.com/kish1n/cpptail">cpptail - Tail Latency Microbenchmarking Tool</a></li>
</ul>

  </main>

  <aside class="post__aside">
    <div class="post__tags">
      
        
        <a href="/tags/cpu/">#cpu</a>
      
        
        <a href="/tags/code/">#code</a>
      
        
        <a href="/tags/vcache/">#vcache</a>
      
        
        <a href="/tags/amd/">#amd</a>
      
        
        <a href="/tags/intel/">#intel</a>
      
    </div>

    <nav class="post__pagination">
    </nav>
  </aside>

</article>
      </main>

      <footer class="footer">
        <div class="footer__content">

          <ul class="hero__social-links">
            
              
                

                
                  
                

                <li>
                  <a href="https://www.linkedin.com/in/ashwin-banwari/" target="_blank" rel="noopener noreferrer" >LinkedIn</a>
                </li>
              
                

                
                  
                

                <li>
                  <a href="https://github.com/kish1n" target="_blank" rel="noopener noreferrer" >GitHub</a>
                </li>
              
            

            

              
            
          </ul>

          

        </div>
      </div>

    </footer>

    <script src="/assets/main.31d6cfe0d16ae931b73c.js"></script>
    
    
  </body>
</html>
